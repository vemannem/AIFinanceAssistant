# Conversation Management - Phase 2C Integration Guide

## What Was Implemented

### âœ… Completed Features

1. **Configuration** (`src/core/config.py`)
   - `CONVERSATION_MAX_HISTORY` - Default: 20 messages
   - `CONVERSATION_SUMMARY_THRESHOLD` - Default: 10 messages
   - `CONVERSATION_SUMMARY_LENGTH` - Default: 500 chars

2. **ConversationManager** (`src/core/conversation_manager.py`)
   - `should_create_summary()` - Check if summary needed
   - `create_summary()` - Generate summary with topics
   - `trim_history()` - Trim to max size + summary
   - `apply_summary_to_prompt()` - Format for LLM
   - `get_stats()` - Get conversation metrics

3. **State Integration** (`src/orchestration/state.py`)
   - `conversation_summary` field added to `OrchestrationState`
   - `get_conversation_context()` method for LLM prompts

4. **Workflow Integration** (`src/orchestration/workflow.py`)
   - `node_input()` now calls `trim_history()`
   - Creates summary when needed automatically
   - Stores summary in state for later use

5. **Tests** (`test_conversation_manager.py`)
   - 6 test cases covering all functionality
   - All tests passing âœ…
   - Phase 2C tests still passing (23/23) âœ…

---

## Architecture

### Data Flow

```
User Input
    â†“
[node_input in workflow]
    â”œâ”€ Add message to conversation_history
    â”œâ”€ Extract as dicts for manager
    â”œâ”€ Call manager.trim_history()
    â”‚  â”œâ”€ Check: len(history) > threshold?
    â”‚  â”œâ”€ YES: Create summary + trim to max
    â”‚  â””â”€ NO: Return as-is
    â”œâ”€ Store summary in state if created
    â””â”€ Continue workflow
```

### State Schema

```python
@dataclass
class OrchestrationState:
    # Existing fields
    user_input: str
    conversation_history: List[Message]  # Recent messages only (trimmed)
    session_id: str
    
    # NEW for conversation management
    conversation_summary: Optional[ConversationSummary] = None
    
    # When getting context for LLM:
    context = state.get_conversation_context()
    # Returns: summary (if exists) + recent messages formatted for LLM
```

---

## Files Modified

### 1. src/core/config.py
**Added**:
```python
# Conversation Management
CONVERSATION_MAX_HISTORY = int(os.getenv("CONVERSATION_MAX_HISTORY", "20"))
CONVERSATION_SUMMARY_LENGTH = int(os.getenv("CONVERSATION_SUMMARY_LENGTH", "500"))
CONVERSATION_SUMMARY_THRESHOLD = int(os.getenv("CONVERSATION_SUMMARY_THRESHOLD", "10"))
```

### 2. src/orchestration/state.py
**Added**:
```python
from src.core.conversation_manager import ConversationSummary

@dataclass
class OrchestrationState:
    conversation_summary: Optional[ConversationSummary] = None
    
    def get_conversation_context(self) -> str:
        """Get conversation context for LLM prompts with summary"""
        manager = get_conversation_manager()
        msg_dicts = [{"role": m.role, "content": m.content} for m in self.conversation_history]
        return manager.apply_summary_to_prompt(msg_dicts, self.conversation_summary)
```

### 3. src/orchestration/workflow.py
**Modified `node_input` method**:
```python
async def node_input(self, state: OrchestrationState) -> OrchestrationState:
    state.add_message("user", state.user_input)
    
    # NEW: Trim conversation history
    msg_dicts = [{"role": m.role, "content": m.content} for m in state.conversation_history]
    trimmed_msgs, summary = self.conversation_manager.trim_history(msg_dicts)
    
    if summary:
        state.conversation_summary = summary
        logger.info(f"Created conversation summary: {len(summary.key_topics)} topics")
    
    return state
```

### 4. src/core/conversation_manager.py
**NEW FILE** (300+ lines):
- ConversationManager class
- ConversationSummary dataclass
- Summary creation with topic extraction
- History trimming algorithm
- Prompt formatting
- Singleton accessor

---

## Usage Examples

### Example 1: Basic Query with Short History

```python
# User's first query
state = OrchestrationState(user_input="What is diversification?")
state.add_message("user", "What is diversification?")
state.add_message("assistant", "Diversification means...")

# In workflow:
state = await workflow.node_input(state)

# History is short (2 messages) â†’ no summary created
assert state.conversation_summary is None
assert len(state.conversation_history) == 2

# Get context for LLM
context = state.get_conversation_context()
# Output: "Recent conversation: User: What is... Assistant: Diversification..."
```

### Example 2: Long Conversation Gets Summarized

```python
# User has been talking for a while (15 messages)
state = OrchestrationState(user_input="How should I rebalance?")
state.conversation_history = [... 14 existing messages + current ...]

# In workflow:
state = await workflow.node_input(state)

# 15 messages > threshold (10) â†’ summary created
assert state.conversation_summary is not None
assert state.conversation_summary.messages_included > 0
assert len(state.conversation_summary.key_topics) > 0

print(f"Topics: {state.conversation_summary.key_topics}")
# Output: Topics: ['Portfolio Analysis', 'Bonds', 'Diversification']

# Get context for LLM (includes summary + recent 5 messages)
context = state.get_conversation_context()
# Output: 
# "Previous conversation summary:
#  Conversation with 15 messages. Main topics: Portfolio Analysis, Bonds...
#  
#  Recent conversation:
#  User: Should I rebalance?
#  ..."
```

### Example 3: Very Long Conversation Gets Trimmed

```python
# User has sent 30 messages (exceeds max of 20)
state = OrchestrationState(user_input="One more question...")
state.conversation_history = [... 29 existing messages + current ...]

# In workflow:
state = await workflow.node_input(state)

# 30 messages > max_history (20) â†’ trimmed to 20 + summary of first 10
assert len(state.conversation_history) == 20  # Trimmed
assert state.conversation_summary is not None  # Summary of 10 old messages
assert state.conversation_summary.messages_included == 10

logger.info("Trimmed conversation history", extra={
    "original_count": 30,
    "trimmed_count": 20,
    "summary_messages": 10
})
```

---

## Integration with Existing Phase 2C System

### âœ… Compatible With

- âœ… Intent Detection (uses full message history)
- âœ… Agent Routing (no changes needed)
- âœ… Agent Execution (agents receive context as parameter)
- âœ… Response Synthesis (uses summary if needed)
- âœ… All 6 agents (Finance QA, Portfolio, Market, Goal, Tax, News)

### âœ… Backwards Compatible

- Existing code unchanged (only additions)
- If summary is None, everything works as before
- Phase 2C tests still pass 100% (23/23)

---

## Test Coverage

### Test File: `test_conversation_manager.py`

```
âœ… test_conversation_manager_basic
   - Create manager
   - Check threshold detection
   - Basic trimming logic

âœ… test_conversation_summary_creation
   - Create summary from messages
   - Extract financial topics (portfolio, bonds, ETF, etc.)
   - Verify summary length limits

âœ… test_trim_history_creates_summary
   - Trim 15 messages to 5
   - Verify summary created for 10 trimmed messages
   - Verify summary metadata

âœ… test_apply_summary_to_prompt
   - Format summary for LLM prompt
   - Include topics and recent messages
   - Verify output is prompt-ready

âœ… test_conversation_stats
   - Get statistics (total, user, assistant messages)
   - Check character counts
   - Verify threshold detection

âœ… test_orchestration_state_conversation
   - Add messages to state
   - Get conversation context
   - Verify context includes history or summary
```

### Running Tests

```bash
# Run conversation manager tests
python test_conversation_manager.py

# Run Phase 2C tests (verify no regression)
python test_phase2c.py

# Expected output:
# âœ… All conversation manager tests passed!
# ðŸ“Š TEST SUMMARY: 23/23 tests passed
```

---

## Configuration for Different Scenarios

### Development Mode

```bash
# .env
CONVERSATION_MAX_HISTORY=100
CONVERSATION_SUMMARY_THRESHOLD=50
CONVERSATION_SUMMARY_LENGTH=1000
```
â†’ Summaries rarely created, longer context allowed

### Production Mode

```bash
# .env
CONVERSATION_MAX_HISTORY=20
CONVERSATION_SUMMARY_THRESHOLD=10
CONVERSATION_SUMMARY_LENGTH=500
```
â†’ Regular summaries, bounded memory usage, ~150 tokens per summary

### High-Volume Mode (Many Users)

```bash
# .env
CONVERSATION_MAX_HISTORY=15
CONVERSATION_SUMMARY_THRESHOLD=8
CONVERSATION_SUMMARY_LENGTH=300
```
â†’ Very tight memory, early summaries, concise summaries

---

## Metrics to Monitor

### In Production

```python
# In response_synthesizer or workflow completion:
logger.info("conversation_metrics", extra={
    "session_id": state.session_id,
    "history_length": len(state.conversation_history),
    "max_history": Config.CONVERSATION_MAX_HISTORY,
    "summary_created": state.conversation_summary is not None,
    "topics_extracted": len(state.conversation_summary.key_topics) if state.conversation_summary else 0,
    "context_chars": len(state.get_conversation_context()),
})
```

### Dashboard Queries

```sql
-- Average history length
SELECT AVG(history_length) FROM conversation_metrics WHERE date > now() - '7 days'::interval

-- Summary creation rate
SELECT COUNT(*) FILTER (WHERE summary_created) * 100.0 / COUNT(*) 
FROM conversation_metrics WHERE date > now() - '7 days'::interval

-- Topics per summary
SELECT AVG(topics_extracted) FROM conversation_metrics 
WHERE summary_created AND date > now() - '7 days'::interval
```

---

## Future Enhancements (Phase 3+)

### Short Term

- [ ] **API Response**: Include summary in API response for frontend display
- [ ] **Dashboard**: Show conversation summary in UI
- [ ] **User Control**: Let users trigger/customize summaries

### Medium Term

- [ ] **Vector Memory**: Store summaries in Pinecone for cross-session context
- [ ] **Persistence**: Save summaries to database
- [ ] **Analytics**: Track topics across users for insights

### Long Term

- [ ] **Smart Summarization**: Use LLM to generate better summaries
- [ ] **Memory Recall**: Retrieve relevant past conversations by topic
- [ ] **Personalization**: Adjust history/summary based on user preferences

---

## Troubleshooting

### Issue: "Conversation history keeps growing"

**Check**:
```python
# Verify manager is being called
# In workflow logs:
logger.info("Trimmed conversation history")  # Should appear periodically

# Verify config
print(Config.CONVERSATION_MAX_HISTORY)  # Should not be > 50
```

**Fix**:
```bash
# .env
CONVERSATION_MAX_HISTORY=20
CONVERSATION_SUMMARY_THRESHOLD=10
```

### Issue: "Summary has no topics"

**Check**:
```python
summary = state.conversation_summary
print(len(summary.key_topics))  # Should be > 0

# Check message content
for msg in state.conversation_history[-5:]:
    print(f"{msg.role}: {msg.content[:50]}")
```

**Fix**: Messages might be too short. Ensure user sends substantive messages (> 20 chars) with financial keywords.

### Issue: "LLM not using context"

**Check**:
```python
context = state.get_conversation_context()
print(f"Context length: {len(context)}")  # Should be > 100

# Verify context in prompt
prompt = f"Context: {context}\nQuestion: {question}"
print(prompt[:500])
```

**Fix**: Ensure prompt template includes `{context}` or `{conversation_history}`.

---

## Summary

**Conversation Management** adds:

âœ… **Max History**: Prevents unbounded growth (default: 20 messages)  
âœ… **Rolling Summary**: Automatic summaries when needed (threshold: 10)  
âœ… **Topic Extraction**: Identifies key topics for context  
âœ… **Zero Breaking Changes**: Fully backwards compatible  
âœ… **Production Ready**: Tested with Phase 2C system  

**Ready for Phase 3**:
- Frontend can display conversation summaries
- API can include summary in responses
- Dashboard can show conversation metrics

**Test Results**:
- âœ… 6/6 conversation manager tests passing
- âœ… 23/23 Phase 2C tests still passing
- âœ… No regressions detected
